{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DIzp4bh5cJs",
        "outputId": "f8040825-e57c-4634-8de2-0a5796650ace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-30 06:32:10--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.15MB/s    in 2m 42s  \n",
            "\n",
            "2023-05-30 06:34:53 (5.09 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GoSwoyy5hZF",
        "outputId": "f60c02e7-5979-439d-d826-87faa132bcd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "!unzip glove.6B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flEvORfi7NXz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmqCEThUUZou",
        "outputId": "3a238cc3-b226-4a10-b4c5-e90cbe40bcbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wEsa7Ir7sTX2"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vCw-ppBWvxPF"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pickle\n",
        "import nltk\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = stopwords.words('english')\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "import gensim\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, GRU, Dense\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNsQWHK3_OYN",
        "outputId": "1f52c281-a424-4f17-88f5-eb694db43730"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ],
      "source": [
        "# !pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "t6kKrBJuwI4m"
      },
      "outputs": [],
      "source": [
        "df  = pd.read_csv('/content/training_set_rel3.tsv', sep='\\t', encoding = \"ISO-8859-1\")\n",
        "# df  = pd.read_csv('/content/Cleaned_Data.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "PZ8R3cwQAUl0",
        "outputId": "3fb993b8-f1bf-4f5e-cce3-adb2e7f2f2e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  Dear local newspaper, I think effects computer...   \n",
              "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
              "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
              "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
              "\n",
              "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
              "0               4               4             NaN              8   \n",
              "1               5               4             NaN              9   \n",
              "2               4               3             NaN              7   \n",
              "3               5               5             NaN             10   \n",
              "4               4               4             NaN              8   \n",
              "\n",
              "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
              "0             NaN             NaN            NaN  ...            NaN   \n",
              "1             NaN             NaN            NaN  ...            NaN   \n",
              "2             NaN             NaN            NaN  ...            NaN   \n",
              "3             NaN             NaN            NaN  ...            NaN   \n",
              "4             NaN             NaN            NaN  ...            NaN   \n",
              "\n",
              "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
              "0            NaN            NaN            NaN            NaN            NaN   \n",
              "1            NaN            NaN            NaN            NaN            NaN   \n",
              "2            NaN            NaN            NaN            NaN            NaN   \n",
              "3            NaN            NaN            NaN            NaN            NaN   \n",
              "4            NaN            NaN            NaN            NaN            NaN   \n",
              "\n",
              "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
              "0            NaN            NaN            NaN            NaN  \n",
              "1            NaN            NaN            NaN            NaN  \n",
              "2            NaN            NaN            NaN            NaN  \n",
              "3            NaN            NaN            NaN            NaN  \n",
              "4            NaN            NaN            NaN            NaN  \n",
              "\n",
              "[5 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-450851ca-3b7a-4041-88f3-fd4aa69b32af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>rater3_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>rater1_domain2</th>\n",
              "      <th>rater2_domain2</th>\n",
              "      <th>domain2_score</th>\n",
              "      <th>...</th>\n",
              "      <th>rater2_trait3</th>\n",
              "      <th>rater2_trait4</th>\n",
              "      <th>rater2_trait5</th>\n",
              "      <th>rater2_trait6</th>\n",
              "      <th>rater3_trait1</th>\n",
              "      <th>rater3_trait2</th>\n",
              "      <th>rater3_trait3</th>\n",
              "      <th>rater3_trait4</th>\n",
              "      <th>rater3_trait5</th>\n",
              "      <th>rater3_trait6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-450851ca-3b7a-4041-88f3-fd4aa69b32af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-450851ca-3b7a-4041-88f3-fd4aa69b32af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-450851ca-3b7a-4041-88f3-fd4aa69b32af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['essay'], df['domain1_score'], test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "btm4Eh54EV31"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm2rxEwyKPBZ",
        "outputId": "c0e63311-5e63-4a1c-b7f2-e1934d4ed7f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10380,)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the text data using GloVe embeddings\n",
        "embedding_dim = 100\n",
        "vocab_size = 10000"
      ],
      "metadata": {
        "id": "GTJosQljEV9i"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_file = '/content/glove.6B.100d.txt'\n",
        "embedding_index = {}\n",
        "with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embedding_index[word] = coefs"
      ],
      "metadata": {
        "id": "2eaBMCnlF68G"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "metadata": {
        "id": "HchEaJPGFFXA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n"
      ],
      "metadata": {
        "id": "K2VbNqxQFFZA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences to the same length\n",
        "max_length = max([len(seq) for seq in X_train_seq])\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_length)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_length)"
      ],
      "metadata": {
        "id": "jHRFAxcaKVnh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scZUx3bhMbBq",
        "outputId": "0558c55f-7540-44a0-e322-16368a9aa02e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36434"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i < vocab_size:\n",
        "        embedding_vector = embedding_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "JZZzp8ZOLU_w"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length, weights=[embedding_matrix], trainable=False))\n",
        "model.add(GRU(100, return_sequences=True))\n",
        "model.add(GRU(64))\n",
        "model.add(Dense(1))"
      ],
      "metadata": {
        "id": "0a72PeA5FFdm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def r2(y_true, y_pred):\n",
        "    SS_res = tf.reduce_sum(tf.square(y_true - y_pred))\n",
        "    SS_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n",
        "    return (1 - SS_res / (SS_tot + tf.keras.backend.epsilon()))"
      ],
      "metadata": {
        "id": "qbUtdVxRMtgu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mean_squared_error', optimizer=RMSprop(lr=0.0006), metrics=['mse', r2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVTWgo9AMtjC",
        "outputId": "f491e140-46f4-4dee-f178-b604bcac238b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n"
      ],
      "metadata": {
        "id": "kkX8-GE7MtlS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train_padded, y_train, batch_size=128, epochs=100, validation_split=0.2, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPyqMo6gMtni",
        "outputId": "c831ec62-2cc3-4956-9c48-982a197d347f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "65/65 [==============================] - 16s 117ms/step - loss: 76.1091 - mse: 76.1091 - r2: 0.0584 - val_loss: 58.2214 - val_mse: 58.2214 - val_r2: 0.2835\n",
            "Epoch 2/100\n",
            "65/65 [==============================] - 6s 90ms/step - loss: 50.2767 - mse: 50.2767 - r2: 0.3795 - val_loss: 41.1221 - val_mse: 41.1221 - val_r2: 0.5006\n",
            "Epoch 3/100\n",
            "65/65 [==============================] - 6s 91ms/step - loss: 40.1575 - mse: 40.1575 - r2: 0.5096 - val_loss: 33.4255 - val_mse: 33.4255 - val_r2: 0.5968\n",
            "Epoch 4/100\n",
            "65/65 [==============================] - 6s 90ms/step - loss: 32.3292 - mse: 32.3292 - r2: 0.5993 - val_loss: 27.3697 - val_mse: 27.3697 - val_r2: 0.6740\n",
            "Epoch 5/100\n",
            "65/65 [==============================] - 6s 92ms/step - loss: 26.1036 - mse: 26.1036 - r2: 0.6845 - val_loss: 23.7423 - val_mse: 23.7423 - val_r2: 0.7143\n",
            "Epoch 6/100\n",
            "65/65 [==============================] - 6s 91ms/step - loss: 21.4680 - mse: 21.4680 - r2: 0.7351 - val_loss: 18.9447 - val_mse: 18.9447 - val_r2: 0.7722\n",
            "Epoch 7/100\n",
            "65/65 [==============================] - 6s 92ms/step - loss: 17.8998 - mse: 17.8998 - r2: 0.7803 - val_loss: 15.6844 - val_mse: 15.6844 - val_r2: 0.8111\n",
            "Epoch 8/100\n",
            "65/65 [==============================] - 6s 91ms/step - loss: 14.8278 - mse: 14.8278 - r2: 0.8168 - val_loss: 13.0771 - val_mse: 13.0771 - val_r2: 0.8410\n",
            "Epoch 9/100\n",
            "65/65 [==============================] - 6s 92ms/step - loss: 11.7789 - mse: 11.7789 - r2: 0.8564 - val_loss: 10.9161 - val_mse: 10.9161 - val_r2: 0.8660\n",
            "Epoch 10/100\n",
            "65/65 [==============================] - 6s 92ms/step - loss: 9.8207 - mse: 9.8207 - r2: 0.8818 - val_loss: 9.3681 - val_mse: 9.3681 - val_r2: 0.8812\n",
            "Epoch 11/100\n",
            "65/65 [==============================] - 6s 90ms/step - loss: 8.0852 - mse: 8.0852 - r2: 0.9019 - val_loss: 7.7827 - val_mse: 7.7827 - val_r2: 0.8998\n",
            "Epoch 12/100\n",
            "65/65 [==============================] - 7s 102ms/step - loss: 6.6489 - mse: 6.6489 - r2: 0.9175 - val_loss: 6.5473 - val_mse: 6.5473 - val_r2: 0.9168\n",
            "Epoch 13/100\n",
            "65/65 [==============================] - 6s 92ms/step - loss: 5.5759 - mse: 5.5759 - r2: 0.9299 - val_loss: 5.6722 - val_mse: 5.6722 - val_r2: 0.9247\n",
            "Epoch 14/100\n",
            "65/65 [==============================] - 6s 93ms/step - loss: 4.7672 - mse: 4.7672 - r2: 0.9396 - val_loss: 4.8608 - val_mse: 4.8608 - val_r2: 0.9353\n",
            "Epoch 15/100\n",
            "65/65 [==============================] - 6s 91ms/step - loss: 4.3135 - mse: 4.3135 - r2: 0.9458 - val_loss: 6.6173 - val_mse: 6.6173 - val_r2: 0.9077\n",
            "Epoch 16/100\n",
            "65/65 [==============================] - 6s 93ms/step - loss: 3.9147 - mse: 3.9147 - r2: 0.9510 - val_loss: 5.0999 - val_mse: 5.0999 - val_r2: 0.9265\n",
            "Epoch 17/100\n",
            "65/65 [==============================] - 6s 92ms/step - loss: 3.6402 - mse: 3.6402 - r2: 0.9539 - val_loss: 4.1648 - val_mse: 4.1648 - val_r2: 0.9413\n",
            "Epoch 18/100\n",
            "65/65 [==============================] - 6s 91ms/step - loss: 3.8709 - mse: 3.8709 - r2: 0.9512 - val_loss: 3.7343 - val_mse: 3.7343 - val_r2: 0.9484\n",
            "Epoch 19/100\n",
            "65/65 [==============================] - 6s 92ms/step - loss: 3.2589 - mse: 3.2589 - r2: 0.9591 - val_loss: 4.3283 - val_mse: 4.3283 - val_r2: 0.9391\n",
            "Epoch 20/100\n",
            "65/65 [==============================] - 6s 93ms/step - loss: 3.3885 - mse: 3.3885 - r2: 0.9571 - val_loss: 4.2730 - val_mse: 4.2730 - val_r2: 0.9424\n",
            "Epoch 21/100\n",
            "65/65 [==============================] - 6s 92ms/step - loss: 3.0445 - mse: 3.0445 - r2: 0.9620 - val_loss: 3.7604 - val_mse: 3.7604 - val_r2: 0.9488\n",
            "Epoch 22/100\n",
            "65/65 [==============================] - 6s 92ms/step - loss: 3.0843 - mse: 3.0843 - r2: 0.9613 - val_loss: 4.1997 - val_mse: 4.1997 - val_r2: 0.9395\n",
            "Epoch 23/100\n",
            "65/65 [==============================] - 6s 92ms/step - loss: 3.0847 - mse: 3.0847 - r2: 0.9614 - val_loss: 3.8370 - val_mse: 3.8370 - val_r2: 0.9466\n",
            "Epoch 24/100\n",
            "65/65 [==============================] - 6s 94ms/step - loss: 2.9550 - mse: 2.9550 - r2: 0.9620 - val_loss: 3.8072 - val_mse: 3.8072 - val_r2: 0.9472\n",
            "Epoch 25/100\n",
            "65/65 [==============================] - 6s 92ms/step - loss: 2.8943 - mse: 2.8943 - r2: 0.9633 - val_loss: 5.1939 - val_mse: 5.1939 - val_r2: 0.9276\n",
            "Epoch 26/100\n",
            "65/65 [==============================] - 6s 93ms/step - loss: 2.8314 - mse: 2.8314 - r2: 0.9647 - val_loss: 3.9181 - val_mse: 3.9181 - val_r2: 0.9467\n",
            "Epoch 27/100\n",
            "65/65 [==============================] - 6s 94ms/step - loss: 2.9372 - mse: 2.9372 - r2: 0.9630 - val_loss: 3.3325 - val_mse: 3.3325 - val_r2: 0.9541\n",
            "Epoch 28/100\n",
            "65/65 [==============================] - 6s 94ms/step - loss: 2.6784 - mse: 2.6784 - r2: 0.9667 - val_loss: 4.3284 - val_mse: 4.3284 - val_r2: 0.9398\n",
            "Epoch 29/100\n",
            "65/65 [==============================] - 6s 94ms/step - loss: 2.6990 - mse: 2.6990 - r2: 0.9661 - val_loss: 4.2732 - val_mse: 4.2732 - val_r2: 0.9412\n",
            "Epoch 30/100\n",
            "65/65 [==============================] - 6s 95ms/step - loss: 2.6573 - mse: 2.6573 - r2: 0.9665 - val_loss: 3.4186 - val_mse: 3.4186 - val_r2: 0.9516\n",
            "Epoch 31/100\n",
            "65/65 [==============================] - 6s 94ms/step - loss: 2.5898 - mse: 2.5898 - r2: 0.9679 - val_loss: 3.1991 - val_mse: 3.1991 - val_r2: 0.9558\n",
            "Epoch 32/100\n",
            "65/65 [==============================] - 6s 95ms/step - loss: 2.4908 - mse: 2.4908 - r2: 0.9686 - val_loss: 3.6648 - val_mse: 3.6648 - val_r2: 0.9494\n",
            "Epoch 33/100\n",
            "65/65 [==============================] - 6s 93ms/step - loss: 2.4262 - mse: 2.4262 - r2: 0.9694 - val_loss: 3.3959 - val_mse: 3.3959 - val_r2: 0.9524\n",
            "Epoch 34/100\n",
            "65/65 [==============================] - 6s 95ms/step - loss: 2.5123 - mse: 2.5123 - r2: 0.9678 - val_loss: 3.4267 - val_mse: 3.4267 - val_r2: 0.9526\n",
            "Epoch 35/100\n",
            "65/65 [==============================] - 6s 93ms/step - loss: 2.3644 - mse: 2.3644 - r2: 0.9702 - val_loss: 3.5327 - val_mse: 3.5327 - val_r2: 0.9507\n",
            "Epoch 36/100\n",
            "65/65 [==============================] - 6s 93ms/step - loss: 2.3932 - mse: 2.3932 - r2: 0.9702 - val_loss: 3.3627 - val_mse: 3.3627 - val_r2: 0.9535\n",
            "Epoch 37/100\n",
            "65/65 [==============================] - 6s 95ms/step - loss: 2.2297 - mse: 2.2297 - r2: 0.9717 - val_loss: 3.3485 - val_mse: 3.3485 - val_r2: 0.9533\n",
            "Epoch 38/100\n",
            "65/65 [==============================] - 6s 94ms/step - loss: 2.4841 - mse: 2.4841 - r2: 0.9688 - val_loss: 3.7817 - val_mse: 3.7817 - val_r2: 0.9476\n",
            "Epoch 39/100\n",
            "65/65 [==============================] - 6s 95ms/step - loss: 2.1973 - mse: 2.1973 - r2: 0.9729 - val_loss: 3.4164 - val_mse: 3.4164 - val_r2: 0.9526\n",
            "Epoch 40/100\n",
            "65/65 [==============================] - 6s 95ms/step - loss: 2.0339 - mse: 2.0339 - r2: 0.9739 - val_loss: 3.3505 - val_mse: 3.3505 - val_r2: 0.9539\n",
            "Epoch 41/100\n",
            "65/65 [==============================] - 6s 94ms/step - loss: 2.0259 - mse: 2.0259 - r2: 0.9747 - val_loss: 3.2393 - val_mse: 3.2393 - val_r2: 0.9550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test_padded)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R-squared:\", r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQbv1ab7Mtp8",
        "outputId": "af7d1a8e-69a8-4a9e-854a-5514683e8eb8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "82/82 [==============================] - 3s 25ms/step\n",
            "Mean Squared Error: 3.208514533305638\n",
            "R-squared: 0.9587901128119531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-WXxWYjpOEI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}